{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "tensorflow version 2.3.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "print('tensorflow version', tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((), ()), types: (tf.string, tf.string)>\n",
      "<DatasetV1Adapter shapes: ((), ()), types: (tf.string, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n",
    "print(train_examples)\n",
    "print(val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .', 'mas e se estes fatores fossem ativos ?', 'mas eles não tinham a curiosidade de me testar .']\n",
      "['and when you improve searchability , you actually take away the one advantage of print , which is serendipity .', 'but what if it were active ?', \"but they did n't test for curiosity .\"]\n"
     ]
    }
   ],
   "source": [
    "pt_text = []\n",
    "en_text = []\n",
    "\n",
    "for pt_example, en_example in train_examples:\n",
    "  pt_text.append(pt_example.numpy().decode('utf-8'))\n",
    "  en_text.append(en_example.numpy().decode('utf-8'))\n",
    "  \n",
    "print(pt_text[:3])\n",
    "print(en_text[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt vocabs:  9000\n",
      "en vocabs:  9000\n"
     ]
    }
   ],
   "source": [
    "def train_tokenizer(text, vocab_size):\n",
    "  tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "  trainer = BpeTrainer(vocab_size=vocab_size, special_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"])\n",
    "  tokenizer.pre_tokenizer = Whitespace()\n",
    "  tokenizer.train_from_iterator(text, trainer)\n",
    "  return tokenizer\n",
    "\n",
    "pt_tokenizer = train_tokenizer(pt_text, 9000)\n",
    "en_tokenizer = train_tokenizer(en_text, 9000)\n",
    "pt_tokenizer.enable_padding()\n",
    "en_tokenizer.enable_padding()\n",
    "print('pt vocabs: ', pt_tokenizer.get_vocab_size())\n",
    "print('en vocabs: ', en_tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   2 1873 1676 ...    0    0    0]\n",
      " [   2 2668   54 ...    0    0    0]\n",
      " [   2  186  695 ...    0    0    0]\n",
      " ...\n",
      " [   2   44  203 ...    0    0    0]\n",
      " [   2  425   14 ...    0    0    0]\n",
      " [   2  302  472 ...    0    0    0]], shape=(32, 70), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[   2 2894  106 ...    0    0    0]\n",
      " [   2  126  289 ...    0    0    0]\n",
      " [   2  164  157 ...    0    0    0]\n",
      " ...\n",
      " [   2  126  223 ...    0    0    0]\n",
      " [   2   99  320 ...    0    0    0]\n",
      " [   2  102  154 ...    0    0    0]], shape=(32, 71), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2894  106  257 ...    0    0    0]\n",
      " [ 126  289    9 ...    0    0    0]\n",
      " [ 164  157  777 ...    0    0    0]\n",
      " ...\n",
      " [ 126  223  146 ...    0    0    0]\n",
      " [  99  320   90 ...    0    0    0]\n",
      " [ 102  154  126 ...    0    0    0]], shape=(32, 71), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def encode_text(pt, en):\n",
    "  pt_text = ['[START] ' + p.decode('utf-8') + ' [END]' for p in pt.numpy()]\n",
    "  en_text = ['[START] ' + e.decode('utf-8') + ' [END]' for e in en.numpy()]\n",
    "  pt_outputs = pt_tokenizer.encode_batch(pt_text)\n",
    "  en_outputs = en_tokenizer.encode_batch(en_text)\n",
    "  pt_ids = [p.ids for p in pt_outputs]\n",
    "  en_ids = [e.ids for e in en_outputs]\n",
    "  return pt_ids, en_ids\n",
    "\n",
    "def tokenization(pt, en):\n",
    "  encoded = tf.py_function(func=encode_text, inp=[pt, en], Tout=[tf.int32, tf.int32])\n",
    "  decoder_input = encoded[1][:, :-1]\n",
    "  decoder_output = encoded[1][:, 1:]\n",
    "  return (encoded[0], decoder_input), decoder_output\n",
    "\n",
    "\n",
    "train_ds = (train_examples\n",
    "            .cache()\n",
    "            .shuffle(BUFFER_SIZE)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .map(tokenization)\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "for (encoder_inputs, decoder_inputs), decoder_outputs in train_ds.take(1):\n",
    "  print(encoder_inputs)\n",
    "  print(decoder_inputs)\n",
    "  print(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length:  245\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "\n",
    "for (encoder_inputs, decoder_inputs), decoder_outputs in train_ds:\n",
    "  max_length = max(max_length, encoder_inputs.shape[1])\n",
    "  max_length = max(max_length, decoder_inputs.shape[1])\n",
    "  max_length = max(max_length, decoder_outputs.shape[1])\n",
    "\n",
    "print('max length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.          0.          0.         ...  1.          1.\n",
      "    1.        ]\n",
      "  [ 0.841471    0.7617204   0.68156135 ...  1.          1.\n",
      "    1.        ]\n",
      "  [ 0.9092974   0.98704624  0.99748    ...  0.99999994  0.99999994\n",
      "    1.        ]\n",
      "  ...\n",
      "  [ 0.37960774  0.7341857  -0.4645332  ...  0.9999034   0.9999276\n",
      "    0.9999457 ]\n",
      "  [-0.57338184 -0.0414884  -0.94348747 ...  0.9999014   0.99992603\n",
      "    0.99994457]\n",
      "  [-0.99920684 -0.78794664 -0.9162827  ...  0.9998994   0.99992454\n",
      "    0.99994344]]], shape=(1, 100, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def positional_encoding(position, size):\n",
    "  pos = tf.range(position)[:, tf.newaxis]\n",
    "  i = tf.range(size)[tf.newaxis, :]\n",
    "  ii = tf.cast((i / 2) * 2, tf.float32)\n",
    "  angle_rads = 1 / tf.pow(10000, ii / size)\n",
    "  angle_rads = tf.cast(pos, tf.float32) * angle_rads\n",
    "\n",
    "  # apply sin to even indices in the array; 2i\n",
    "  sin = tf.sin(angle_rads[:, 0::2])\n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  cos = tf.cos(angle_rads[:, 1::2])\n",
    "  pos_encoding = tf.concat([sin, cos], axis=-1)\n",
    "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "pos_en = positional_encoding(100, 128)\n",
    "print(pos_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_padding mask:  (32, 53, 53)\n",
      "look ahead mask:  (32, 56, 56)\n",
      "decoder_padding mask: (32, 56, 53)\n",
      "look ahead mask:  tf.Tensor(\n",
      "[[[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(32, 56, 56), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x, key_size):\n",
    "  seq = tf.cast(tf.logical_not(tf.equal(x, 0)), tf.float32)\n",
    "  seq = seq[:, tf.newaxis, :]\n",
    "  return tf.transpose(tf.tile(seq, [1, key_size, 1]), [0, 2, 1])\n",
    "\n",
    "def create_look_ahead_mask(x_length, y_length):\n",
    "  mask = tf.linalg.band_part(tf.ones((x_length, y_length)), -1, 0)\n",
    "  return mask\n",
    "\n",
    "def create_masks(x, y):\n",
    "  x_length = tf.shape(x)[1]\n",
    "  y_length = tf.shape(y)[1]\n",
    "  encoder_padding_mask = create_padding_mask(x, x_length)\n",
    "  decoder_padding_mask1 = create_padding_mask(y, y_length)\n",
    "  decoder_padding_mask2 = create_padding_mask(y, x_length)\n",
    "  look_ahead_mask = create_look_ahead_mask(y_length, y_length)\n",
    "  combined_mask = tf.minimum(decoder_padding_mask1, look_ahead_mask)\n",
    "  return encoder_padding_mask, combined_mask, decoder_padding_mask2\n",
    "\n",
    "\n",
    "for (encoder_inputs, decoder_inputs), decoder_outputs in train_ds.take(1):\n",
    "  encoder_padding_mask, combined_mask, decoder_padding_mask = create_masks(encoder_inputs, decoder_inputs)\n",
    "  print('encoder_padding mask: ', encoder_padding_mask.shape)\n",
    "  print('look ahead mask: ', combined_mask.shape)\n",
    "  print('decoder_padding mask:', decoder_padding_mask.shape)\n",
    "  print('look ahead mask: ', combined_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal (TensorFlowOp [(None, None)]       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LogicalNot (TensorF [(None, None)]       0           tf_op_layer_Equal[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlowOpL [(None, None)]       0           tf_op_layer_LogicalNot[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range (TensorFlowOp [(None,)]            0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 1, None)]    0           tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile/multiples (Ten [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 128)    1152000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 128)          32000       tf_op_layer_Range[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile (TensorFlowOpL [(None, None, None)] 0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_Tile/multiples[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, None, 128)]  0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose (TensorFl [(None, None, None)] 0           tf_op_layer_Tile[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, None, 128)    524416      tf_op_layer_AddV2[0][0]          \n",
      "                                                                 tf_op_layer_AddV2[0][0]          \n",
      "                                                                 tf_op_layer_AddV2[0][0]          \n",
      "                                                                 tf_op_layer_Transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 128)    0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, None, 128)]  0           dropout_1[0][0]                  \n",
      "                                                                 tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, None, 128)    256         tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 512)    66048       layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 128)    65664       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 128)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, None, 128)]  0           dropout_2[0][0]                  \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, None, 128)    256         tf_op_layer_AddV2_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, None, 128)    524416      layer_normalization_1[0][0]      \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "                                                                 tf_op_layer_Transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 128)    0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, None, 128)]  0           dropout_4[0][0]                  \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, None, 128)    256         tf_op_layer_AddV2_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 512)    66048       layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 128)    65664       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 128)    0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorFlow [(None, None, 128)]  0           dropout_5[0][0]                  \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, None, 128)    256         tf_op_layer_AddV2_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, None, 128)    524416      layer_normalization_3[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "                                                                 tf_op_layer_Transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 128)    0           multi_head_attention_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow [(None, None, 128)]  0           dropout_7[0][0]                  \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, None, 128)    256         tf_op_layer_AddV2_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 512)    66048       layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, None, 128)    65664       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, None, 128)    0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal_1 (TensorFlow [(None, None)]       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_7 (TensorFlow [(None, None, 128)]  0           dropout_8[0][0]                  \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LogicalNot_1 (Tenso [(None, None)]       0           tf_op_layer_Equal_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, None, 128)    256         tf_op_layer_AddV2_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_1 (TensorFlowO [(None, None)]       0           tf_op_layer_LogicalNot_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, None, 128)    524416      layer_normalization_5[0][0]      \n",
      "                                                                 layer_normalization_5[0][0]      \n",
      "                                                                 layer_normalization_5[0][0]      \n",
      "                                                                 tf_op_layer_Transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 1, None)]    0           tf_op_layer_Cast_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_1/multiples (T [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_packed (TensorFlowO [(2,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, 128)    0           multi_head_attention_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_1 (TensorFlow [(None,)]            0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_1 (TensorFlowO [(None, None, None)] 0           tf_op_layer_strided_slice_3[0][0]\n",
      "                                                                 tf_op_layer_Tile_1/multiples[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Fill (TensorFlowOpL [(None, None)]       0           tf_op_layer_packed[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_8 (TensorFlow [(None, None, 128)]  0           dropout_10[0][0]                 \n",
      "                                                                 layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    1152000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 128)          32000       tf_op_layer_Range_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_1 (Tensor [(None, None, None)] 0           tf_op_layer_Tile_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatrixBandPart (Ten [(None, None)]       0           tf_op_layer_Fill[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, None, 128)    256         tf_op_layer_AddV2_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal_2 (TensorFlow [(None, None)]       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, None, 128)]  0           embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Minimum (TensorFlow [(None, None, None)] 0           tf_op_layer_Transpose_1[0][0]    \n",
      "                                                                 tf_op_layer_MatrixBandPart[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 512)    66048       layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LogicalNot_2 (Tenso [(None, None)]       0           tf_op_layer_Equal_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, None, 128)    524416      tf_op_layer_AddV2_1[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_1[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_1[0][0]        \n",
      "                                                                 tf_op_layer_Minimum[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 128)    65664       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_2 (TensorFlowO [(None, None)]       0           tf_op_layer_LogicalNot_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 128)    0           multi_head_attention_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, 128)    0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 1, None)]    0           tf_op_layer_Cast_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_2/multiples (T [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_10 (TensorFlo [(None, None, 128)]  0           dropout_13[0][0]                 \n",
      "                                                                 tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_9 (TensorFlow [(None, None, 128)]  0           dropout_11[0][0]                 \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_2 (TensorFlowO [(None, None, None)] 0           tf_op_layer_strided_slice_4[0][0]\n",
      "                                                                 tf_op_layer_Tile_2/multiples[0][0\n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, None, 128)    256         tf_op_layer_AddV2_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, None, 128)    256         tf_op_layer_AddV2_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_2 (Tensor [(None, None, None)] 0           tf_op_layer_Tile_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, None, 128)    524416      layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "                                                                 tf_op_layer_Transpose_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, None, 128)    0           multi_head_attention_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_11 (TensorFlo [(None, None, 128)]  0           dropout_15[0][0]                 \n",
      "                                                                 layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, None, 128)    256         tf_op_layer_AddV2_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, None, 512)    66048       layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 128)    65664       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, None, 128)    0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_12 (TensorFlo [(None, None, 128)]  0           dropout_16[0][0]                 \n",
      "                                                                 layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, None, 128)    524416      layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "                                                                 tf_op_layer_Minimum[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, None, 128)    0           multi_head_attention_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_13 (TensorFlo [(None, None, 128)]  0           dropout_18[0][0]                 \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, None, 128)    524416      layer_normalization_11[0][0]     \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "                                                                 tf_op_layer_Transpose_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, None, 128)    0           multi_head_attention_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_14 (TensorFlo [(None, None, 128)]  0           dropout_20[0][0]                 \n",
      "                                                                 layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, None, 512)    66048       layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, None, 128)    65664       dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, None, 128)    0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_15 (TensorFlo [(None, None, 128)]  0           dropout_21[0][0]                 \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe (None, None, 128)    524416      layer_normalization_13[0][0]     \n",
      "                                                                 layer_normalization_13[0][0]     \n",
      "                                                                 layer_normalization_13[0][0]     \n",
      "                                                                 tf_op_layer_Minimum[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, None, 128)    0           multi_head_attention_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_16 (TensorFlo [(None, None, 128)]  0           dropout_23[0][0]                 \n",
      "                                                                 layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_9 (MultiHe (None, None, 128)    524416      layer_normalization_14[0][0]     \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "                                                                 tf_op_layer_Transpose_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, None, 128)    0           multi_head_attention_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_17 (TensorFlo [(None, None, 128)]  0           dropout_25[0][0]                 \n",
      "                                                                 layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, None, 512)    66048       layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, None, 128)    65664       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, None, 128)    0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_18 (TensorFlo [(None, None, 128)]  0           dropout_26[0][0]                 \n",
      "                                                                 layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_10 (MultiH (None, None, 128)    524416      layer_normalization_16[0][0]     \n",
      "                                                                 layer_normalization_16[0][0]     \n",
      "                                                                 layer_normalization_16[0][0]     \n",
      "                                                                 tf_op_layer_Minimum[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, None, 128)    0           multi_head_attention_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_19 (TensorFlo [(None, None, 128)]  0           dropout_28[0][0]                 \n",
      "                                                                 layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_11 (MultiH (None, None, 128)    524416      layer_normalization_17[0][0]     \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "                                                                 tf_op_layer_Transpose_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, None, 128)    0           multi_head_attention_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_20 (TensorFlo [(None, None, 128)]  0           dropout_30[0][0]                 \n",
      "                                                                 layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_18 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, None, 512)    66048       layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, None, 128)    65664       dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, None, 128)    0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_21 (TensorFlo [(None, None, 128)]  0           dropout_31[0][0]                 \n",
      "                                                                 layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, None, 128)    256         tf_op_layer_AddV2_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, None, 9000)   1161000     layer_normalization_19[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 10,880,808\n",
      "Trainable params: 10,880,808\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "MAX_LENGTH = 250\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 4\n",
    "DENSE_OUTPUT = 512\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "def embedding(x, vocab_size):\n",
    "  length = tf.shape(x)[1]\n",
    "  position = tf.range(start=0, limit=length, delta=1)\n",
    "  em = layers.Embedding(vocab_size, EMBEDDING_SIZE)(x)\n",
    "  pos_em = layers.Embedding(MAX_LENGTH, EMBEDDING_SIZE)(position)\n",
    "  return em + pos_em\n",
    "\n",
    "def encoder(x, mask):\n",
    "  m = tfa.layers.MultiHeadAttention(EMBEDDING_SIZE, NUM_HEADS)([x, x, x], mask=mask)\n",
    "  d = layers.Dropout(DROPOUT_RATE)(m)\n",
    "  n = layers.LayerNormalization(epsilon=1e-6)(d + x)\n",
    "  x = layers.Dense(DENSE_OUTPUT, activation='relu')(n)\n",
    "  x = layers.Dense(EMBEDDING_SIZE)(x)\n",
    "  d = layers.Dropout(DROPOUT_RATE)(x)\n",
    "  x = layers.LayerNormalization(epsilon=1e-6)(d + n)\n",
    "  return x\n",
    "\n",
    "def decoder(k, v, q, look_ahead_mask, padding_mask):\n",
    "  m = tfa.layers.MultiHeadAttention(EMBEDDING_SIZE, NUM_HEADS)([q, q, q], mask=look_ahead_mask)\n",
    "  d = layers.Dropout(DROPOUT_RATE)(m)\n",
    "  n = layers.LayerNormalization(epsilon=1e-6)(d + q)\n",
    "  \n",
    "  m = tfa.layers.MultiHeadAttention(EMBEDDING_SIZE, NUM_HEADS)([n, k, v], mask=padding_mask)\n",
    "  d = layers.Dropout(DROPOUT_RATE)(m)\n",
    "  n = layers.LayerNormalization(epsilon=1e-6)(d + n)\n",
    "  \n",
    "  x = layers.Dense(DENSE_OUTPUT, activation='relu')(n)\n",
    "  x = layers.Dense(EMBEDDING_SIZE)(x)\n",
    "  d = layers.Dropout(DROPOUT_RATE)(x)\n",
    "  x = layers.LayerNormalization(epsilon=1e-6)(d + n)\n",
    "  return x\n",
    "\n",
    "\n",
    "def create_model():\n",
    "  encoder_inputs = layers.Input(shape=[None], dtype=tf.int32)\n",
    "  decoder_inputs = layers.Input(shape=[None], dtype=tf.int32)\n",
    "  encoder_mask, look_ahead_mask, decoder_padding_mask = create_masks(encoder_inputs, decoder_inputs)\n",
    "  e = embedding(encoder_inputs, pt_tokenizer.get_vocab_size())\n",
    "  d = embedding(decoder_inputs, en_tokenizer.get_vocab_size())\n",
    "  for _ in range(NUM_LAYERS):\n",
    "    e = encoder(e, encoder_mask)\n",
    "  for _ in range(NUM_LAYERS):\n",
    "    d = decoder(e, e, d, look_ahead_mask, decoder_padding_mask)\n",
    "  outputs = layers.Dense(en_tokenizer.get_vocab_size(), activation='softmax')(d)\n",
    "  model = keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=[outputs])\n",
    "  return model\n",
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs:  (32, 97)\n",
      "decoder_inputs:  (32, 101)\n",
      "prediction:  (32, 101, 9000)\n",
      "prediction tensor:  (32, 101, 9000)\n",
      "decoder_outputs:  (32, 101)\n",
      "softmax result:  tf.Tensor(\n",
      "[[8052 4154 4154 ... 7792 6967 8639]\n",
      " [1981 7393 4154 ... 3718 1550 2657]\n",
      " [1981 4154 4154 ... 3718 1550 2657]\n",
      " ...\n",
      " [1981 4154 4154 ... 3718 1550 2657]\n",
      " [1981 4154 4154 ... 3718 1550 2657]\n",
      " [8888 7393 4154 ... 3718 1550 2657]], shape=(32, 101), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[1.17449265e-04 8.14972445e-05 2.03551215e-04 ... 1.74050801e-04\n",
      "   7.88674079e-05 9.99307013e-05]\n",
      "  [1.19461562e-04 9.45702195e-05 1.53504763e-04 ... 1.51525310e-04\n",
      "   7.99787304e-05 1.06491425e-04]\n",
      "  [1.39074415e-04 9.08720613e-05 1.74228247e-04 ... 1.39343159e-04\n",
      "   8.47972769e-05 1.20650722e-04]\n",
      "  ...\n",
      "  [1.36129733e-04 1.03933045e-04 1.43667363e-04 ... 1.33304682e-04\n",
      "   9.47814115e-05 1.46123100e-04]\n",
      "  [1.26654253e-04 8.41241781e-05 1.44574980e-04 ... 1.35737471e-04\n",
      "   8.14384839e-05 1.32193993e-04]\n",
      "  [1.25492661e-04 8.03852672e-05 1.03422055e-04 ... 1.25753562e-04\n",
      "   8.96204947e-05 1.36260060e-04]]\n",
      "\n",
      " [[1.19566663e-04 8.32176302e-05 1.89873521e-04 ... 1.49038809e-04\n",
      "   8.20325004e-05 8.76879421e-05]\n",
      "  [1.06319640e-04 9.22055551e-05 1.61733682e-04 ... 1.33351437e-04\n",
      "   8.26901451e-05 9.94329384e-05]\n",
      "  [1.42743927e-04 9.54291390e-05 1.64026424e-04 ... 1.34941656e-04\n",
      "   8.46045950e-05 1.14414055e-04]\n",
      "  ...\n",
      "  [1.26935105e-04 7.22024779e-05 1.34448623e-04 ... 1.30124739e-04\n",
      "   1.00333877e-04 1.11121968e-04]\n",
      "  [1.04943647e-04 7.18709052e-05 1.47283805e-04 ... 1.40153206e-04\n",
      "   8.39002751e-05 1.16678268e-04]\n",
      "  [1.11774709e-04 7.54507200e-05 1.15134826e-04 ... 1.22399593e-04\n",
      "   1.04279876e-04 1.17257303e-04]]\n",
      "\n",
      " [[1.19476361e-04 8.31621655e-05 1.91197614e-04 ... 1.49549378e-04\n",
      "   8.21025533e-05 8.80278749e-05]\n",
      "  [1.21844962e-04 9.10903109e-05 1.66901606e-04 ... 1.39210722e-04\n",
      "   8.89637013e-05 9.25276909e-05]\n",
      "  [1.57497401e-04 9.10231756e-05 1.61030708e-04 ... 1.42683100e-04\n",
      "   8.14567320e-05 1.08194712e-04]\n",
      "  ...\n",
      "  [1.27514839e-04 7.19207674e-05 1.34654852e-04 ... 1.30320288e-04\n",
      "   1.00444791e-04 1.11748050e-04]\n",
      "  [1.05697400e-04 7.18339361e-05 1.48315245e-04 ... 1.40253105e-04\n",
      "   8.38763372e-05 1.17382813e-04]\n",
      "  [1.12209716e-04 7.55138972e-05 1.15133902e-04 ... 1.22044476e-04\n",
      "   1.04256556e-04 1.18230731e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.19617100e-04 8.31759753e-05 1.90879495e-04 ... 1.49939995e-04\n",
      "   8.21508584e-05 8.78330029e-05]\n",
      "  [1.21576129e-04 9.12108953e-05 1.66499565e-04 ... 1.39827491e-04\n",
      "   8.91104719e-05 9.23623884e-05]\n",
      "  [1.50188833e-04 9.19124577e-05 1.59900606e-04 ... 1.38093499e-04\n",
      "   8.67256967e-05 1.08751097e-04]\n",
      "  ...\n",
      "  [1.28690634e-04 7.18192096e-05 1.34678048e-04 ... 1.31269771e-04\n",
      "   1.00738485e-04 1.11593479e-04]\n",
      "  [1.05600731e-04 7.18074443e-05 1.48206425e-04 ... 1.41370823e-04\n",
      "   8.39534187e-05 1.17057207e-04]\n",
      "  [1.12473055e-04 7.55299188e-05 1.15044160e-04 ... 1.23135382e-04\n",
      "   1.04450723e-04 1.18103453e-04]]\n",
      "\n",
      " [[1.18296397e-04 8.25907409e-05 1.94408261e-04 ... 1.52296823e-04\n",
      "   8.18127592e-05 8.97466089e-05]\n",
      "  [1.19425349e-04 9.10990057e-05 1.68810555e-04 ... 1.39764161e-04\n",
      "   8.87680872e-05 9.42423721e-05]\n",
      "  [1.25823630e-04 7.67003003e-05 1.51471657e-04 ... 1.30847271e-04\n",
      "   9.49496462e-05 1.06012980e-04]\n",
      "  ...\n",
      "  [1.28894433e-04 7.19230011e-05 1.35816896e-04 ... 1.31557390e-04\n",
      "   1.00763253e-04 1.15233794e-04]\n",
      "  [1.04733139e-04 7.22218683e-05 1.52153647e-04 ... 1.43665733e-04\n",
      "   8.40104331e-05 1.20080542e-04]\n",
      "  [1.10203488e-04 7.57613816e-05 1.15536095e-04 ... 1.25157167e-04\n",
      "   1.04351784e-04 1.23438062e-04]]\n",
      "\n",
      " [[1.18701944e-04 8.22176007e-05 1.96606154e-04 ... 1.56316659e-04\n",
      "   8.15581807e-05 9.19666054e-05]\n",
      "  [1.14319708e-04 9.32904222e-05 1.60350246e-04 ... 1.30421467e-04\n",
      "   8.72646633e-05 1.04723949e-04]\n",
      "  [1.23775229e-04 1.12981914e-04 1.66685626e-04 ... 1.32608388e-04\n",
      "   9.66912703e-05 1.08405584e-04]\n",
      "  ...\n",
      "  [1.29803841e-04 7.13245463e-05 1.36424933e-04 ... 1.34830116e-04\n",
      "   1.02529710e-04 1.19206692e-04]\n",
      "  [1.03799670e-04 7.08115840e-05 1.53221452e-04 ... 1.46060862e-04\n",
      "   8.48540658e-05 1.24886312e-04]\n",
      "  [1.08658642e-04 7.51442494e-05 1.15847608e-04 ... 1.27959196e-04\n",
      "   1.06533727e-04 1.28565516e-04]]], shape=(32, 101, 9000), dtype=float32)\n",
      "loss:  tf.Tensor(9.115857, shape=(), dtype=float32)\n",
      "accuracy:  tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "  mask = tf.logical_not(tf.equal(y_true, 0))\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  loss = keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "  return tf.reduce_sum(loss * mask) / tf.reduce_sum(mask)\n",
    "\n",
    "def accuracy_fn(real, pred):\n",
    "  accuracies = tf.equal(tf.cast(real, tf.int64), tf.argmax(pred, axis=2))\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "for (encoder_inputs, decoder_inputs), decoder_outputs in train_ds.take(1):\n",
    "  print('encoder_inputs: ', encoder_inputs.shape)\n",
    "  print('decoder_inputs: ', decoder_inputs.shape)\n",
    "  inputs = (tf.convert_to_tensor(encoder_inputs), tf.convert_to_tensor(decoder_inputs))\n",
    "  prediction = model.predict(inputs)\n",
    "  print('prediction: ', prediction.shape)\n",
    "  decoder_pred = model(inputs)\n",
    "  print('prediction tensor: ', decoder_pred.shape)\n",
    "  print('decoder_outputs: ', decoder_outputs.shape)\n",
    "  print('softmax result: ', tf.argmax(decoder_pred, axis=-1))\n",
    "  loss = loss_fn(decoder_outputs, decoder_pred)\n",
    "  print(decoder_pred)\n",
    "  print('loss: ', loss)\n",
    "  acc = accuracy_fn(decoder_outputs, decoder_pred)\n",
    "  print('accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),\n",
    "              loss=loss_fn, metrics=[accuracy_fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 1/20\n",
      "      1/Unknown - 0s 34us/step - loss: 9.1121 - accuracy_fn: 0.0000e+00WARNING:tensorflow:From /home/kiddos/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kiddos/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1619/1619 [==============================] - 173s 107ms/step - loss: 5.7916 - accuracy_fn: 0.2012\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 2/20\n",
      "1619/1619 [==============================] - 176s 108ms/step - loss: 4.5471 - accuracy_fn: 0.3293\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 3/20\n",
      "1619/1619 [==============================] - 172s 106ms/step - loss: 4.0486 - accuracy_fn: 0.3850\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 4/20\n",
      "1619/1619 [==============================] - 168s 103ms/step - loss: 3.6855 - accuracy_fn: 0.4252\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 5/20\n",
      "1619/1619 [==============================] - 164s 101ms/step - loss: 3.3923 - accuracy_fn: 0.4581\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 6/20\n",
      "1619/1619 [==============================] - 164s 101ms/step - loss: 3.1432 - accuracy_fn: 0.4857\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 7/20\n",
      "1619/1619 [==============================] - 168s 104ms/step - loss: 2.9286 - accuracy_fn: 0.5101\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 8/20\n",
      "1619/1619 [==============================] - 170s 105ms/step - loss: 2.7385 - accuracy_fn: 0.5322\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 9/20\n",
      "1619/1619 [==============================] - 171s 106ms/step - loss: 2.5707 - accuracy_fn: 0.5516\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 10/20\n",
      "1619/1619 [==============================] - 170s 105ms/step - loss: 2.4223 - accuracy_fn: 0.5687\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 11/20\n",
      "1619/1619 [==============================] - 167s 103ms/step - loss: 2.2128 - accuracy_fn: 0.5983\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 12/20\n",
      "1619/1619 [==============================] - 167s 103ms/step - loss: 2.1534 - accuracy_fn: 0.6062\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 13/20\n",
      "1619/1619 [==============================] - 169s 104ms/step - loss: 2.1049 - accuracy_fn: 0.6129\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 14/20\n",
      "1619/1619 [==============================] - 168s 104ms/step - loss: 2.0629 - accuracy_fn: 0.6177\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 15/20\n",
      "1619/1619 [==============================] - 167s 103ms/step - loss: 2.0226 - accuracy_fn: 0.6230\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 16/20\n",
      "1619/1619 [==============================] - 167s 103ms/step - loss: 1.9850 - accuracy_fn: 0.6275\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 17/20\n",
      "1619/1619 [==============================] - 168s 104ms/step - loss: 1.9534 - accuracy_fn: 0.6312\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 18/20\n",
      "1619/1619 [==============================] - 169s 104ms/step - loss: 1.9229 - accuracy_fn: 0.6345\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 19/20\n",
      "1619/1619 [==============================] - 169s 104ms/step - loss: 1.8971 - accuracy_fn: 0.6377\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 20/20\n",
      "1619/1619 [==============================] - 168s 104ms/step - loss: 1.8704 - accuracy_fn: 0.6409\n"
     ]
    }
   ],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch == 0:\n",
    "    return 1e-4\n",
    "  if epoch == 10:\n",
    "    return 3e-5\n",
    "  return lr\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir='translation_logs')\n",
    "schedule_callback = callbacks.LearningRateScheduler(scheduler, verbose=True)\n",
    "\n",
    "history = model.fit(train_ds, epochs=EPOCHS, callbacks=[schedule_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 44, 284, 458, 193, 40, 1864, 14, 5841, 40, 1233, 4658, 136, 4001, 14, 130, 86, 40, 226, 147, 160, 321, 206, 16, 3]]\n",
      "[[2]]\n",
      "[2, 99, 255, 117, 634, 292, 93, 90, 868, 13, 117, 428, 90, 419, 3891, 106, 90, 6582, 13, 331, 97, 90, 158, 120, 92, 163, 1659, 15, 3]\n",
      "and when you better look at the search , you take the only advantage of the impression , which is the un be re di vor .\n"
     ]
    }
   ],
   "source": [
    "def translate(pt):\n",
    "  pt_encoded = pt_tokenizer.encode('[START] ' + pt + ' [END]')\n",
    "  encoder_inputs = [pt_encoded.ids]\n",
    "  decoder_inputs = [en_tokenizer.encode('[START]').ids]\n",
    "  stop_token = en_tokenizer.encode('[END]').ids[0]\n",
    "  print(encoder_inputs)\n",
    "  print(decoder_inputs)\n",
    "  for i in range(MAX_LENGTH-1):\n",
    "    encoder_input_tensor = tf.convert_to_tensor(encoder_inputs)\n",
    "    decoder_input_tensor = tf.convert_to_tensor(decoder_inputs)\n",
    "    p = model((encoder_input_tensor, decoder_input_tensor), training=False)\n",
    "    token = np.argmax(p[0, -1, :])\n",
    "    decoder_inputs[0].append(token)\n",
    "    if token == stop_token:\n",
    "      break\n",
    "  print(decoder_inputs[0])\n",
    "  return en_tokenizer.decode(decoder_inputs[0])\n",
    "\n",
    "\n",
    "pt = 'e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .'\n",
    "en = translate(pt)\n",
    "print(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('translation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiddos/.local/lib/python3.6/site-packages/tensorflowjs/converters/keras_h5_conversion.py:123: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  return h5py.File(h5file)\n"
     ]
    }
   ],
   "source": [
    "import tensorflowjs as tfjs\n",
    "\n",
    "tfjs.converters.save_keras_model(model, 'translation.tfjs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('translation.tfjs/vocab.json', 'w') as f:\n",
    "  vocabs = {\n",
    "    'en': en_tokenizer.get_vocab(),\n",
    "    'pt': pt_tokenizer.get_vocab(),\n",
    "  }\n",
    "  json.dump(vocabs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
