{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed8e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517e60cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "PATCH_SIZE = 4\n",
    "EXPANSION_FACTOR = 2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LABEL_SMOOTHING_FACTOR = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc3418b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  <PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n",
      "validation:  <PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = tfds.load('tf_flowers', split=['train[:90%]', 'train[90%:]'], as_supervised=True)\n",
    "\n",
    "print('training: ', train_dataset)\n",
    "print('validation: ', val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83073a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=3303>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31451253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=367>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413420f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 256, 256, 3), (None, 5)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "LARGER_IMAGE_SIZE = 280\n",
    "\n",
    "def random_jitter(image, label):\n",
    "    image = tf.image.resize(image, [LARGER_IMAGE_SIZE, LARGER_IMAGE_SIZE])\n",
    "    image = tf.image.random_crop(image, [IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # image = tf.image.random_jpeg_quality(image, 80, 100)\n",
    "    label = tf.one_hot(label, 5)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_ds = train_dataset.map(random_jitter).batch(BATCH_SIZE)\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e510e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 256, 256, 3), (None, 5)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "    label = tf.one_hot(label, 5)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "val_ds = val_dataset.map(preprocess_image).batch(BATCH_SIZE)\n",
    "print(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e07cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 32) 512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu (TFOpLambda)         (None, 128, 128, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseConv (None, 128, 128, 32) 288         tf.nn.silu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 32) 128         depthwise_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_1 (TFOpLambda)       (None, 128, 128, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 512         tf.nn.silu_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, 128, 16) 0           batch_normalization_2[0][0]      \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 32) 512         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_2 (TFOpLambda)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 130, 130, 32) 0           tf.nn.silu_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 64, 64, 32)   288         zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 32)   128         depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_3 (TFOpLambda)       (None, 64, 64, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 24)   768         tf.nn.silu_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 24)   96          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 48)   1152        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 48)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_4 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 64, 64, 48)   432         tf.nn.silu_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 48)   192         depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_5 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 24)   1152        tf.nn.silu_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 24)   96          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 24)   0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 48)   1152        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 48)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_6 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (None, 64, 64, 48)   432         tf.nn.silu_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 48)   192         depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_7 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 24)   1152        tf.nn.silu_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 24)   96          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 24)   0           batch_normalization_11[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 48)   1152        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 48)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_8 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 66, 66, 48)   0           tf.nn.silu_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (None, 32, 32, 48)   432         zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 48)   192         depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_9 (TFOpLambda)       (None, 32, 32, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 48)   2304        tf.nn.silu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 48)   192         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 64)   27712       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 64)   4160        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4, 256, 64)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 4, 256, 64)   128         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4, 256, 128)  8320        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4, 256, 128)  0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 4, 256, 64)   128         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4, 256, 64)   8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 4, 256, 64)   33216       layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4, 256, 64)   0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 256, 64)   0           multi_head_attention[0][0]       \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 256, 64)   0           dropout_1[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 4, 256, 64)   128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4, 256, 128)  8320        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 256, 128)  0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 4, 256, 64)   128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4, 256, 64)   8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 4, 256, 64)   33216       layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4, 256, 64)   0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 256, 64)   0           multi_head_attention_1[0][0]     \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 256, 64)   0           dropout_3[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 32, 32, 64)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 48)   3120        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 96)   0           batch_normalization_14[0][0]     \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 64)   55360       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 128)  8192        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_10 (TFOpLambda)      (None, 32, 32, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 34, 34, 128)  0           tf.nn.silu_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_5 (DepthwiseCo (None, 16, 16, 128)  1152        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         depthwise_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_11 (TFOpLambda)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 64)   8192        tf.nn.silu_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 80)   46160       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 80)   6480        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 4, 64, 80)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 4, 64, 80)    160         reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4, 64, 160)   12960       layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4, 64, 160)   0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 4, 64, 80)    160         reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4, 64, 80)    12880       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 4, 64, 80)    51760       layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 64, 80)    0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 64, 80)    0           multi_head_attention_2[0][0]     \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 64, 80)    0           dropout_5[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 4, 64, 80)    160         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4, 64, 160)   12960       layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 4, 64, 160)   0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 4, 64, 80)    160         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 4, 64, 80)    12880       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 4, 64, 80)    51760       layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 4, 64, 80)    0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 64, 80)    0           multi_head_attention_3[0][0]     \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 4, 64, 80)    0           dropout_7[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 4, 64, 80)    160         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4, 64, 160)   12960       layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4, 64, 160)   0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 4, 64, 80)    160         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 4, 64, 80)    12880       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 4, 64, 80)    51760       layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 4, 64, 80)    0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 64, 80)    0           multi_head_attention_4[0][0]     \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 64, 80)    0           dropout_9[0][0]                  \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, 4, 64, 80)    160         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4, 64, 160)   12960       layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 4, 64, 160)   0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, 4, 64, 80)    160         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4, 64, 80)    12880       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 4, 64, 80)    51760       layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 4, 64, 80)    0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 4, 64, 80)    0           multi_head_attention_5[0][0]     \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 64, 80)    0           dropout_11[0][0]                 \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 16, 16, 80)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   5184        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 128)  0           batch_normalization_17[0][0]     \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 80)   92240       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 160)  12800       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 160)  640         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_12 (TFOpLambda)      (None, 16, 16, 160)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 18, 18, 160)  0           tf.nn.silu_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_6 (DepthwiseCo (None, 8, 8, 160)    1440        zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 160)    640         depthwise_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_13 (TFOpLambda)      (None, 8, 8, 160)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 80)     12800       tf.nn.silu_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 80)     320         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 96)     69216       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 96)     9312        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 4, 16, 96)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 4, 16, 96)    192         reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4, 16, 192)   18624       layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 4, 16, 192)   0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 4, 16, 96)    192         reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 4, 16, 96)    18528       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, 4, 16, 96)    74400       layer_normalization_12[0][0]     \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 4, 16, 96)    0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 16, 96)    0           multi_head_attention_6[0][0]     \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 16, 96)    0           dropout_13[0][0]                 \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, 4, 16, 96)    192         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4, 16, 192)   18624       layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 4, 16, 192)   0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 4, 16, 96)    192         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 4, 16, 96)    18528       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, 4, 16, 96)    74400       layer_normalization_14[0][0]     \n",
      "                                                                 layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 4, 16, 96)    0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 4, 16, 96)    0           multi_head_attention_7[0][0]     \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 4, 16, 96)    0           dropout_15[0][0]                 \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, 4, 16, 96)    192         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 4, 16, 192)   18624       layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 4, 16, 192)   0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 4, 16, 96)    192         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 4, 16, 96)    18528       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe (None, 4, 16, 96)    74400       layer_normalization_16[0][0]     \n",
      "                                                                 layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 4, 16, 96)    0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 4, 16, 96)    0           multi_head_attention_8[0][0]     \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 4, 16, 96)    0           dropout_17[0][0]                 \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 8, 8, 96)     0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 80)     7760        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 160)    0           batch_normalization_20[0][0]     \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 96)     138336      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 320)    31040       conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 320)          0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 5)            1605        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 1,307,621\n",
      "Trainable params: 1,305,077\n",
      "Non-trainable params: 2,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def inverted_residual(x, expanded_channels, output_channels, strides=1):\n",
    "    m = layers.Conv2D(expanded_channels, 1, padding=\"same\", use_bias=False)(x)\n",
    "    m = layers.BatchNormalization()(m)\n",
    "    m = tf.nn.swish(m)\n",
    "\n",
    "    padding = 'same'\n",
    "    if strides == 2:\n",
    "        m = layers.ZeroPadding2D(padding=[1,1])(m)\n",
    "        padding = 'valid'\n",
    "    m = layers.DepthwiseConv2D(3, strides=strides, padding=padding, use_bias=False)(m)\n",
    "    m = layers.BatchNormalization()(m)\n",
    "    m = tf.nn.swish(m)\n",
    "\n",
    "    m = layers.Conv2D(output_channels, 1, padding=\"same\", use_bias=False)(m)\n",
    "    m = layers.BatchNormalization()(m)\n",
    "\n",
    "    if tf.math.equal(x.shape[-1], output_channels) and strides == 1:\n",
    "        return layers.Add()([m, x])\n",
    "    return m\n",
    "\n",
    "\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for unit in hidden_units:\n",
    "        x = layers.Dense(unit, activation=tf.nn.swish)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def transformer(x, num_layers, projection, num_heads=2):\n",
    "    norm = partial(layers.LayerNormalization, epsilon=1e-6)\n",
    "    for _ in range(num_layers):\n",
    "        x1 = norm()(x)\n",
    "        attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection, dropout=0.1)(x1, x1)\n",
    "        x2 = layers.Add()([attention, x])\n",
    "        x3 = norm()(x)\n",
    "        x3 = mlp(x3, [x.shape[-1]*2, x.shape[-1]], 0.1)\n",
    "        x = layers.Add()([x3, x2])\n",
    "    return x\n",
    "\n",
    "\n",
    "def vit(x, num_blocks, projection, strides=1):\n",
    "    local = layers.Conv2D(projection, 3, padding='same', strides=strides, activation=tf.nn.swish)(x)\n",
    "    local = layers.Conv2D(projection, 1, padding='same', strides=strides, activation=tf.nn.swish)(local)\n",
    "    num_patches = int((local.shape[1] * local.shape[2]) / PATCH_SIZE)\n",
    "    patches = layers.Reshape((PATCH_SIZE, num_patches, projection))(local)\n",
    "    global_features = transformer(patches, num_blocks, projection)\n",
    "    folded = layers.Reshape((*local.shape[1:-1], projection))(global_features)\n",
    "    folded = layers.Conv2D(x.shape[-1], 1, padding='same', strides=strides, activation=tf.nn.swish)(folded)\n",
    "    features = layers.Concatenate(axis=-1)([x, folded])\n",
    "    features = layers.Conv2D(projection, 3, padding='same', strides=strides, activation=tf.nn.swish)(features)\n",
    "    return features\n",
    "\n",
    "\n",
    "def create_mobilevit(output_size):\n",
    "    inputs = layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    \n",
    "    x = layers.Conv2D(16, 3, strides=2, padding='same', activation=tf.nn.swish)(inputs)\n",
    "    x = inverted_residual(x, 16 * EXPANSION_FACTOR, 16)\n",
    "    \n",
    "    x = inverted_residual(x, 16 * EXPANSION_FACTOR, 24, strides=2)\n",
    "    x = inverted_residual(x, 24 * EXPANSION_FACTOR, 24)\n",
    "    x = inverted_residual(x, 24 * EXPANSION_FACTOR, 24)\n",
    "    \n",
    "    x = inverted_residual(x, 24 * EXPANSION_FACTOR, 48, strides=2)\n",
    "    x = vit(x, 2, 64)\n",
    "    \n",
    "    x = inverted_residual(x, 64 * EXPANSION_FACTOR, 64, strides=2)\n",
    "    x = vit(x, 4, 80)\n",
    "\n",
    "    x = inverted_residual(x, 80 * EXPANSION_FACTOR, 80, strides=2)\n",
    "    x = vit(x, 3, 96)\n",
    "    \n",
    "    x = layers.Conv2D(320, 1, padding='same', strides=1, activation=tf.nn.swish)(x)\n",
    "    x = layers.GlobalAvgPool2D()(x)\n",
    "    outputs = layers.Dense(output_size, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "    \n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = create_mobilevit(5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d22713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "learning rate: 0.0020000000949949026\n",
      "  6/104 [>.............................] - ETA: 25s - loss: 1.6332 - accuracy: 0.3281WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1130s vs `on_train_batch_end` time: 0.1262s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1130s vs `on_train_batch_end` time: 0.1262s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 38s 283ms/step - loss: 1.3396 - accuracy: 0.4850 - val_loss: 1.7643 - val_accuracy: 0.1907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "learning rate: 0.0019979961216449738\n",
      "104/104 [==============================] - 27s 264ms/step - loss: 1.1228 - accuracy: 0.6285 - val_loss: 2.1099 - val_accuracy: 0.1907\n",
      "Epoch 3/50\n",
      "learning rate: 0.0019919921178370714\n",
      "104/104 [==============================] - 27s 260ms/step - loss: 1.0637 - accuracy: 0.6576 - val_loss: 2.2463 - val_accuracy: 0.1907\n",
      "Epoch 4/50\n",
      "learning rate: 0.0019820125307887793\n",
      "104/104 [==============================] - 27s 263ms/step - loss: 1.0141 - accuracy: 0.6848 - val_loss: 2.2150 - val_accuracy: 0.2343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "learning rate: 0.0019680969417095184\n",
      "104/104 [==============================] - 28s 265ms/step - loss: 0.9733 - accuracy: 0.7091 - val_loss: 1.3511 - val_accuracy: 0.5286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "learning rate: 0.0019503012299537659\n",
      "104/104 [==============================] - 28s 267ms/step - loss: 0.9596 - accuracy: 0.7139 - val_loss: 1.1735 - val_accuracy: 0.5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "learning rate: 0.0019286967581138015\n",
      "104/104 [==============================] - 28s 268ms/step - loss: 0.9488 - accuracy: 0.7224 - val_loss: 1.0359 - val_accuracy: 0.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "learning rate: 0.0019033702556043863\n",
      "104/104 [==============================] - 28s 268ms/step - loss: 0.9172 - accuracy: 0.7345 - val_loss: 1.0124 - val_accuracy: 0.6921\n",
      "Epoch 9/50\n",
      "learning rate: 0.001874422887340188\n",
      "104/104 [==============================] - 28s 267ms/step - loss: 0.9013 - accuracy: 0.7499 - val_loss: 0.9083 - val_accuracy: 0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "learning rate: 0.0018419709522277117\n",
      "104/104 [==============================] - 28s 271ms/step - loss: 0.8588 - accuracy: 0.7744 - val_loss: 0.9788 - val_accuracy: 0.7057\n",
      "Epoch 11/50\n",
      "learning rate: 0.0018061446025967598\n",
      "104/104 [==============================] - 27s 260ms/step - loss: 0.8364 - accuracy: 0.7778 - val_loss: 0.9965 - val_accuracy: 0.7193\n",
      "Epoch 12/50\n",
      "learning rate: 0.0017670870292931795\n",
      "104/104 [==============================] - 27s 263ms/step - loss: 0.8184 - accuracy: 0.7917 - val_loss: 1.0672 - val_accuracy: 0.6649\n",
      "Epoch 13/50\n",
      "learning rate: 0.0017249551601707935\n",
      "104/104 [==============================] - 28s 266ms/step - loss: 0.8063 - accuracy: 0.8002 - val_loss: 0.8842 - val_accuracy: 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "learning rate: 0.001679917797446251\n",
      "104/104 [==============================] - 28s 268ms/step - loss: 0.7898 - accuracy: 0.8056 - val_loss: 1.0036 - val_accuracy: 0.7084\n",
      "Epoch 15/50\n",
      "learning rate: 0.0016321552684530616\n",
      "104/104 [==============================] - 28s 269ms/step - loss: 0.7767 - accuracy: 0.8108 - val_loss: 0.9173 - val_accuracy: 0.7221\n",
      "Epoch 16/50\n",
      "learning rate: 0.001581858959980309\n",
      "104/104 [==============================] - 27s 262ms/step - loss: 0.7652 - accuracy: 0.8141 - val_loss: 0.9650 - val_accuracy: 0.7112\n",
      "Epoch 17/50\n",
      "learning rate: 0.0015292306197807193\n",
      "104/104 [==============================] - 27s 262ms/step - loss: 0.7534 - accuracy: 0.8253 - val_loss: 0.8368 - val_accuracy: 0.7629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "learning rate: 0.0014744813088327646\n",
      "104/104 [==============================] - 28s 264ms/step - loss: 0.7220 - accuracy: 0.8404 - val_loss: 0.8044 - val_accuracy: 0.8011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "learning rate: 0.001417830353602767\n",
      "104/104 [==============================] - 28s 268ms/step - loss: 0.7186 - accuracy: 0.8468 - val_loss: 0.8655 - val_accuracy: 0.7793\n",
      "Epoch 20/50\n",
      "learning rate: 0.0013595045311376452\n",
      "104/104 [==============================] - 27s 264ms/step - loss: 0.7050 - accuracy: 0.8523 - val_loss: 0.8490 - val_accuracy: 0.7575\n",
      "Epoch 21/50\n",
      "learning rate: 0.0012997378362342715\n",
      "104/104 [==============================] - 28s 269ms/step - loss: 0.6866 - accuracy: 0.8601 - val_loss: 0.8464 - val_accuracy: 0.7711\n",
      "Epoch 22/50\n",
      "learning rate: 0.0012387699680402875\n",
      "104/104 [==============================] - 28s 268ms/step - loss: 0.6816 - accuracy: 0.8653 - val_loss: 0.7725 - val_accuracy: 0.8120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "learning rate: 0.0011768450494855642\n",
      "104/104 [==============================] - 28s 266ms/step - loss: 0.6557 - accuracy: 0.8774 - val_loss: 0.8161 - val_accuracy: 0.7956\n",
      "Epoch 24/50\n",
      "learning rate: 0.0011142113944515586\n",
      "104/104 [==============================] - 27s 263ms/step - loss: 0.6438 - accuracy: 0.8862 - val_loss: 0.9443 - val_accuracy: 0.7166\n",
      "Epoch 25/50\n",
      "learning rate: 0.0010511199943721294\n",
      "104/104 [==============================] - 27s 259ms/step - loss: 0.6316 - accuracy: 0.8907 - val_loss: 0.7895 - val_accuracy: 0.8174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "learning rate: 0.000987823586910963\n",
      "104/104 [==============================] - 28s 269ms/step - loss: 0.6210 - accuracy: 0.8949 - val_loss: 0.8156 - val_accuracy: 0.7929\n",
      "Epoch 27/50\n",
      "learning rate: 0.000924576073884964\n",
      "104/104 [==============================] - 28s 271ms/step - loss: 0.6027 - accuracy: 0.9068 - val_loss: 0.7855 - val_accuracy: 0.8202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "learning rate: 0.0008616308332420886\n",
      "104/104 [==============================] - 28s 266ms/step - loss: 0.5928 - accuracy: 0.9116 - val_loss: 0.8193 - val_accuracy: 0.8038\n",
      "Epoch 29/50\n",
      "learning rate: 0.0007992401951923966\n",
      "104/104 [==============================] - 28s 264ms/step - loss: 0.5779 - accuracy: 0.9216 - val_loss: 0.7649 - val_accuracy: 0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "learning rate: 0.0007376540452241898\n",
      "104/104 [==============================] - 28s 269ms/step - loss: 0.5738 - accuracy: 0.9249 - val_loss: 0.7536 - val_accuracy: 0.8202\n",
      "Epoch 31/50\n",
      "learning rate: 0.0006771195912733674\n",
      "104/104 [==============================] - 28s 272ms/step - loss: 0.5552 - accuracy: 0.9340 - val_loss: 0.8148 - val_accuracy: 0.7984\n",
      "Epoch 32/50\n",
      "learning rate: 0.0006178790354169905\n",
      "104/104 [==============================] - 28s 271ms/step - loss: 0.5501 - accuracy: 0.9367 - val_loss: 0.7281 - val_accuracy: 0.8365\n",
      "Epoch 33/50\n",
      "learning rate: 0.0005601702141575515\n",
      "104/104 [==============================] - 28s 272ms/step - loss: 0.5371 - accuracy: 0.9419 - val_loss: 0.7571 - val_accuracy: 0.8338\n",
      "Epoch 34/50\n",
      "learning rate: 0.0005042242119088769\n",
      "104/104 [==============================] - 27s 264ms/step - loss: 0.5407 - accuracy: 0.9391 - val_loss: 0.7228 - val_accuracy: 0.8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "learning rate: 0.0004502648371271789\n",
      "104/104 [==============================] - 28s 268ms/step - loss: 0.5248 - accuracy: 0.9491 - val_loss: 0.6867 - val_accuracy: 0.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "learning rate: 0.00039850923349149525\n",
      "104/104 [==============================] - 28s 265ms/step - loss: 0.5117 - accuracy: 0.9582 - val_loss: 0.7036 - val_accuracy: 0.8556\n",
      "Epoch 37/50\n",
      "learning rate: 0.00034916415461339056\n",
      "104/104 [==============================] - 28s 265ms/step - loss: 0.5101 - accuracy: 0.9564 - val_loss: 0.6932 - val_accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "learning rate: 0.000302427593851462\n",
      "104/104 [==============================] - 27s 262ms/step - loss: 0.5051 - accuracy: 0.9567 - val_loss: 0.6868 - val_accuracy: 0.8638\n",
      "Epoch 39/50\n",
      "learning rate: 0.00025848689256235957\n",
      "104/104 [==============================] - 28s 266ms/step - loss: 0.4960 - accuracy: 0.9625 - val_loss: 0.6844 - val_accuracy: 0.8556\n",
      "Epoch 40/50\n",
      "learning rate: 0.00021751809981651604\n",
      "104/104 [==============================] - 28s 269ms/step - loss: 0.4894 - accuracy: 0.9667 - val_loss: 0.6704 - val_accuracy: 0.8610\n",
      "Epoch 41/50\n",
      "learning rate: 0.00017968547763302922\n",
      "104/104 [==============================] - 27s 264ms/step - loss: 0.4790 - accuracy: 0.9728 - val_loss: 0.6811 - val_accuracy: 0.8638\n",
      "Epoch 42/50\n",
      "learning rate: 0.00014514077338390052\n",
      "104/104 [==============================] - 27s 262ms/step - loss: 0.4762 - accuracy: 0.9758 - val_loss: 0.6703 - val_accuracy: 0.8692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "learning rate: 0.00011402214295230806\n",
      "104/104 [==============================] - 28s 270ms/step - loss: 0.4698 - accuracy: 0.9776 - val_loss: 0.6573 - val_accuracy: 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "learning rate: 8.645451453048736e-05\n",
      "104/104 [==============================] - 27s 262ms/step - loss: 0.4686 - accuracy: 0.9794 - val_loss: 0.6622 - val_accuracy: 0.8610\n",
      "Epoch 45/50\n",
      "learning rate: 6.254828622331843e-05\n",
      "104/104 [==============================] - 27s 264ms/step - loss: 0.4611 - accuracy: 0.9837 - val_loss: 0.6673 - val_accuracy: 0.8719\n",
      "Epoch 46/50\n",
      "learning rate: 4.239934787619859e-05\n",
      "104/104 [==============================] - 27s 263ms/step - loss: 0.4640 - accuracy: 0.9776 - val_loss: 0.6680 - val_accuracy: 0.8665\n",
      "Epoch 47/50\n",
      "learning rate: 2.608847717056051e-05\n",
      "104/104 [==============================] - 27s 264ms/step - loss: 0.4561 - accuracy: 0.9843 - val_loss: 0.6625 - val_accuracy: 0.8665\n",
      "Epoch 48/50\n",
      "learning rate: 1.3680875781574287e-05\n",
      "104/104 [==============================] - 27s 263ms/step - loss: 0.4615 - accuracy: 0.9785 - val_loss: 0.6577 - val_accuracy: 0.8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 270). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "learning rate: 5.226493158261292e-06\n",
      "104/104 [==============================] - 27s 261ms/step - loss: 0.4575 - accuracy: 0.9849 - val_loss: 0.6580 - val_accuracy: 0.8774\n",
      "Epoch 50/50\n",
      "learning rate: 7.590651875943877e-07\n",
      "104/104 [==============================] - 28s 267ms/step - loss: 0.4595 - accuracy: 0.9837 - val_loss: 0.6574 - val_accuracy: 0.8774\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.6577 - accuracy: 0.8801\n",
      "validation accuracy: 88.01%\n"
     ]
    }
   ],
   "source": [
    "class LogLearningRate(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr(self.model.optimizer.iterations)\n",
    "        print(f'learning rate: {lr.numpy()}')\n",
    "\n",
    "\n",
    "def run_experiment(model, epochs):\n",
    "    checkpoint_path = '/tmp/checkpoint'\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path, monitor='val_accuracy', save_best_only=True)\n",
    "    log_lr_callback = LogLearningRate()\n",
    "    \n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint_callback, log_lr_callback])\n",
    "    \n",
    "    model.load_weights(checkpoint_path)\n",
    "    _, accuracy = model.evaluate(val_ds)\n",
    "    print(f'validation accuracy: {round(accuracy * 100, 2)}%')\n",
    "    return model\n",
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING_FACTOR)\n",
    "\n",
    "decay_steps = int(len(train_dataset) / BATCH_SIZE * EPOCHS)\n",
    "lr = tf.keras.optimizers.schedules.CosineDecay(2e-3, decay_steps)\n",
    "optimizer = keras.optimizers.Adam(lr)\n",
    "\n",
    "model = create_mobilevit(5)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "model = run_experiment(model, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4862ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
